{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3a6f3c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'prophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_13000/1606934805.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mprophet\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mProphet\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"figure.figsize\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m14\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'prophet'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.tsa.api import Holt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from prophet import Prophet\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (14, 8)\n",
    "import wrangle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42098c3",
   "metadata": {},
   "source": [
    "# Acquisition, prep, and split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1495f960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pulling in all data, cleaning and displaying info\n",
    "aquifer, temps, precip, pop, usage = wrangle.get_dataframes()\n",
    "aquifer, weather, pop, usage = wrangle.clean_all_dataframes(aquifer, temps, precip, pop, usage)\n",
    "aquifer.info(), weather.info(), pop.info(), usage.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b80dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting train size to be 60% of the total dataset\n",
    "train_size = int(round(aquifer.shape[0] * 0.6))\n",
    "\n",
    "# set validate size to be 25% of the total dataset\n",
    "validate_size = int(round(aquifer.shape[0] * 0.25))\n",
    "\n",
    "# Setting test size to be 15% of the total dataset. \n",
    "test_size = int(round(aquifer.shape[0] * 0.15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "841518ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to make sure the split worked\n",
    "len(aquifer) == train_size + validate_size + test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e54a3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_end_index = train_size + validate_size\n",
    "validate_end_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186ec378",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = aquifer[:train_size]\n",
    "validate = aquifer[train_size:validate_end_index]\n",
    "test = aquifer[validate_end_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "923ecb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the split to see if the starting and ending values for train, validate and test line up properly.\n",
    "train.tail(1), validate.head(1), validate.tail(1), test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a4ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting out the splits to visualize them\n",
    "plt.plot(train)\n",
    "plt.plot(validate)\n",
    "plt.plot(test)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4116658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making sure the datasets have accurate frequency data\n",
    "train = train.asfreq('d', method='bfill')\n",
    "validate = validate.asfreq('d', method='bfill')\n",
    "test = test.asfreq('d', method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2108b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(target_var):\n",
    "    '''\n",
    "    This function takes in the actual values of the target_var from validate, and the predicted values stored in yhat_df, \n",
    "    and computes the rmse, rounding to 0 decimal places. Finally it returns the rmse. \n",
    "    '''\n",
    "    rmse = round((mean_squared_error(validate[target_var], yhat_df[target_var]))**(1/2), 0)\n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef8f92d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_and_eval(target_var):\n",
    "    '''\n",
    "    This function takes in the target var name (string), and returns a plot\n",
    "    of the values of train for that variable, validate, and the predicted values from yhat_df. \n",
    "    it will als lable the rmse. \n",
    "    '''\n",
    "    plt.figure(figsize = (12,4))\n",
    "    plt.plot(train[target_var], label='Train', linewidth=1)\n",
    "    plt.plot(validate[target_var], label='Validate', linewidth=1)\n",
    "    plt.plot(yhat_df[target_var])\n",
    "    plt.title(target_var)\n",
    "    rmse = evaluate(target_var)\n",
    "    print(target_var, '-- RMSE: {:.0f}'.format(rmse))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1209dd2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty dataframe\n",
    "eval_df = pd.DataFrame(columns=['model_type', 'target_var', 'rmse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8f29fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to store the rmse so that we can compare\n",
    "def append_eval_df(model_type, target_var):\n",
    "    '''\n",
    "    this function takes in as arguments the type of model run, and the name of the target variable. \n",
    "    It returns the eval_df with the rmse appended to it for that model and target_var. \n",
    "    '''\n",
    "    rmse = evaluate(target_var)\n",
    "    d = {'model_type': [model_type], 'target_var': [target_var],\n",
    "        'rmse': [rmse]}\n",
    "    d = pd.DataFrame(d)\n",
    "    return eval_df.append(d, ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4ec519",
   "metadata": {},
   "source": [
    "# Modeling, Forecasting, Predicting\n",
    "\n",
    "For modeling I will start with some basic predictions in order to acquire a baseline.\n",
    "1. Last Observed Value: This will predict that future values will look like the most recent value.\n",
    "2. Simple Average: This will predict that future values will look like a historical average. \n",
    "3. Moving Average: This will predict that future values will look like a recent period of time's average. \n",
    "\n",
    "Then I will move into more predictive models: \n",
    "\n",
    "4. Holt's Linear Trend\n",
    "5. Previous Cycle\n",
    "\n",
    "And finally if given time I want to try either:\n",
    "\n",
    "6. Facebook Prophet\n",
    "7. LinkedIn Greykite"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230260fd",
   "metadata": {},
   "source": [
    "### Last observed value\n",
    "\n",
    "The simplest method for forecasting is to predict all future values to be the last observed value.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grabbing the most recent observation in train and assigning it to a variable\n",
    "last_observed_level = train['water_level_elevation'][-1:][0]\n",
    "last_observed_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2422b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame({'water_level_elevation': [last_observed_level]}, index=validate.index)\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e46746f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('water_level_elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545a0253",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = append_eval_df(model_type = 'last_observed_value', target_var = 'water_level_elevation')\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d5cd7a",
   "metadata": {},
   "source": [
    "### Simple Average\n",
    "\n",
    "This takes the historical average and uses that to predict future values.   \n",
    "\n",
    "This is a possible good option for an initial baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2255c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the historical mean\n",
    "avg_elevation = round(train['water_level_elevation'].mean(), 2)\n",
    "avg_elevation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a628c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df = pd.DataFrame({'water_level_elevation': [avg_elevation]}, index=validate.index)\n",
    "yhat_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803fed37",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('water_level_elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd93ca5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = append_eval_df(model_type = 'avg_elevation', target_var = 'water_level_elevation')\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b870a39a",
   "metadata": {},
   "source": [
    "### Moving Average\n",
    "\n",
    "I will use a range of different rolling averages to see which works the best."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406160c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "periods = [7, 14, 30, 60, 365, 730, 1825, 3650]\n",
    "\n",
    "for p in periods: \n",
    "    rolling_water_levels = round(train['water_level_elevation'].rolling(p).mean()[-1], 2)\n",
    "    yhat_df = pd.DataFrame({'water_level_elevation': [rolling_water_levels]},\n",
    "                          index=validate.index)\n",
    "    model_type = str(p) + '_day_moving_avg'\n",
    "    for col in train.columns:\n",
    "        eval_df = append_eval_df(model_type = model_type,\n",
    "                                target_var = col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc3ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60f5777e",
   "metadata": {},
   "source": [
    "The best performing model so far is the 730 day (2 year) moving avg with an RMSE of 17 although the overall average isn't farm behind with an RMSE of 18. So going forward the 730_day_moving_avg will be my baseline with RMSE of 17."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4750be0",
   "metadata": {},
   "source": [
    "### Holt's Linear Trend\n",
    "\n",
    "For the initial Holt's model I'm going to use base settings and tweak hyperparameters later if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3d2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the initial Holt's Object\n",
    "model = Holt(train, exponential=False, damped=True)\n",
    "# Fitting the Holt's object\n",
    "model = model.fit(optimized=True)\n",
    "#Making predictions for each date in validate\n",
    "yhat_items = model.predict(start = validate.index[0], end = validate.index[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "105fa6d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking to make sure the length of validate matches the number of predictions given in my yhat_tems\n",
    "validate.shape, yhat_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ce9b5e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to yhat_df\n",
    "yhat_df['water_level_elevation'] = pd.DataFrame(yhat_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "204c1590",
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6243c17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_and_eval('water_level_elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae3af6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_df = append_eval_df(model_type = 'holts_optimized', target_var = 'water_level_elevation')\n",
    "eval_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b524e6",
   "metadata": {},
   "source": [
    "Holt's linear trend model performed terribly. Since there is no identifiable previous cycle, I can't use this method to predict future values.\n",
    "\n",
    "I will need to find a better model if I am going to beat baseline, but it's entirely possible there is no model that will accurately predict this based on water level elevation data alone since it's seemingly random. Thus univariate time series forecasts would not be possible. Taking into account other variable data could would be valuable but as it stands this is beyond the scope of this project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1b16f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
